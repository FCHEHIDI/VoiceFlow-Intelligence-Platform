# üìã CAHIER DES CHARGES - VoiceFlow Intelligence Platform

## 1. PR√âSENTATION DU PROJET

### 1.1 Contexte
VoiceFlow Intelligence Platform est un syst√®me de traitement audio temps-r√©el con√ßu pour identifier automatiquement les locuteurs dans un flux audio (Speaker Diarization). Le syst√®me doit √™tre production-ready avec une architecture hybride optimisant √† la fois la flexibilit√© du Machine Learning et la performance du traitement temps-r√©el.

### 1.2 Objectifs Globaux
- Fournir un service de speaker diarization avec latence < 100ms pour le streaming temps-r√©el
- Supporter √† la fois le traitement batch et le streaming en temps-r√©el
- Architecture scalable et maintenable pour un environnement de production
- Pipeline MLOps complet (CI/CD, monitoring, containerization)

### 1.3 P√©rim√®tre
**Inclus:**
- Service ML Python pour l'entra√Ænement et la gestion des mod√®les
- Service Rust pour l'inf√©rence temps-r√©el haute performance
- API REST pour le traitement batch
- WebSocket pour le streaming temps-r√©el
- Infrastructure Docker compl√®te
- Monitoring et observabilit√© (Prometheus + Grafana)
- CI/CD automatis√©
- Documentation technique compl√®te

**Exclu:**
- Interface utilisateur web (frontend)
- Int√©gration avec des services tiers sp√©cifiques
- Gestion avanc√©e des droits utilisateurs (au-del√† de JWT basic)
- Support multilingue de la documentation

---

## 2. ACTEURS DU SYST√àME

### 2.1 ML Engineers
**R√¥le:** D√©veloppement et optimisation des mod√®les de diarization
**Besoins:**
- API pour d√©clencher des entra√Ænements
- Export de mod√®les vers ONNX
- M√©triques de performance des mod√®les
- Versioning des mod√®les
- Interface pour t√©l√©charger datasets

**Interactions:**
- Utilisation du service Python via API REST
- Acc√®s aux logs d'entra√Ænement
- Visualisation des m√©triques dans Grafana

### 2.2 DevOps / SRE
**R√¥le:** D√©ploiement et maintenance de l'infrastructure
**Besoins:**
- Configuration Docker Compose simple
- Health checks et readiness probes
- Monitoring syst√®me (CPU, m√©moire, latence)
- Logs structur√©s centralis√©s
- CI/CD automatis√©

**Interactions:**
- D√©ploiement via Docker Compose
- Surveillance via Grafana dashboards
- Alerting via Prometheus

### 2.3 End Users / Applications Clientes
**R√¥le:** Consommation des services de diarization
**Besoins:**
- API REST pour traitement batch d'audio
- WebSocket pour streaming temps-r√©el
- Documentation API claire (OpenAPI/Swagger)
- Authentification s√©curis√©e (JWT)
- Rate limiting pour √©viter les abus

**Interactions:**
- Envoi de fichiers audio via HTTP POST
- Connexion WebSocket pour streaming
- R√©ception des r√©sultats (JSON avec timestamps et speaker labels)

### 2.4 Data Scientists
**R√¥le:** Analyse des performances et am√©lioration continue
**Besoins:**
- Acc√®s aux m√©triques d'inf√©rence
- Audit trail des pr√©dictions
- Export des r√©sultats pour analyse
- Dashboard de performance des mod√®les

**Interactions:**
- Requ√™tes SQL sur base PostgreSQL (metrics, audit_logs)
- Visualisation via Grafana

---

## 3. FONCTIONNALIT√âS PRINCIPALES

### 3.1 F1: Speaker Diarization Temps-R√©el (Priorit√©: CRITIQUE)
**Description:** Identification en temps-r√©el des locuteurs dans un flux audio

**Sp√©cifications:**
- **Input:** Audio stream (WebSocket) @ 16kHz, mono, PCM
- **Output:** Segments JSON avec `{start_time, end_time, speaker_id, confidence}`
- **Latence:** < 100ms (P99)
- **Format audio support√©:** WAV, PCM raw, MP3 (d√©cod√© c√¥t√© client)

**Sc√©narios d'usage:**
1. Client √©tablit connexion WebSocket `/ws/stream`
2. Client envoie chunks audio de 1 seconde
3. Service Rust traite en temps-r√©el
4. R√©sultats stream√©s imm√©diatement au client

**Contraintes:**
- Thread-safe (plusieurs connexions simultan√©es)
- Gestion gracieuse des d√©connexions
- Buffer overflow prevention

### 3.2 F2: Traitement Batch Audio (Priorit√©: HAUTE)
**Description:** Upload et traitement asynchrone de fichiers audio complets

**Sp√©cifications:**
- **Input:** Fichier audio (POST multipart/form-data)
- **Taille max:** 100 MB
- **Dur√©e max:** 30 minutes
- **Output:** Job ID imm√©diat, r√©sultats r√©cup√©rables via polling ou webhook

**Endpoints:**
- `POST /api/inference/batch` ‚Üí Job ID
- `GET /api/inference/batch/{job_id}` ‚Üí Status + r√©sultats

**Workflow:**
1. Client upload fichier
2. Service Python valide et enqueue job
3. Worker traite asynchrone (Celery ou RQ)
4. R√©sultats stock√©s en DB + optionnel callback webhook
5. Client poll status ou re√ßoit webhook

### 3.3 F3: Gestion des Mod√®les (Priorit√©: HAUTE)
**Description:** Entra√Ænement, versioning, et d√©ploiement de mod√®les ML

**Fonctionnalit√©s:**
- **Entra√Ænement:** `POST /api/models/train` avec hyperparam√®tres
- **Export ONNX:** `POST /api/models/{model_id}/export`
- **Listing:** `GET /api/models` (avec filtres: version, status, date)
- **Activation:** `PUT /api/models/{model_id}/activate` (set as production model)
- **Rollback:** `PUT /api/models/{previous_id}/activate`

**M√©tadonn√©es mod√®le:**
```json
{
  "model_id": "uuid",
  "version": "1.2.3",
  "architecture": "ResNet-LSTM",
  "training_date": "2025-11-29T10:00:00Z",
  "accuracy": 0.92,
  "status": "active|deprecated",
  "onnx_path": "/models/model-v1.2.3.onnx"
}
```

### 3.4 F4: A/B Testing Mod√®les (Priorit√©: MOYENNE)
**Description:** Test de nouveaux mod√®les sur un pourcentage du trafic

**Sp√©cifications:**
- Configuration: 90% mod√®le actuel, 10% nouveau mod√®le
- Routing bas√© sur hash user_id (consistant)
- M√©triques s√©par√©es par mod√®le version
- Comparaison automatique latence + accuracy

**Configuration:**
```yaml
model_routing:
  - model_version: "1.2.3"
    traffic_percent: 90
  - model_version: "1.3.0-beta"
    traffic_percent: 10
```

### 3.5 F5: Monitoring et Observabilit√© (Priorit√©: CRITIQUE)
**Description:** Visibilit√© compl√®te sur syst√®me et performances

**M√©triques Rust Service:**
- `inference_latency_seconds` (histogram)
- `inference_requests_total` (counter)
- `inference_errors_total` (counter)
- `websocket_connections_active` (gauge)
- `model_load_duration_seconds` (histogram)

**M√©triques Python Service:**
- `training_duration_seconds` (histogram)
- `model_accuracy` (gauge)
- `batch_job_duration_seconds` (histogram)
- `batch_queue_size` (gauge)

**Dashboards Grafana:**
1. Real-Time Inference (latency, throughput, error rate)
2. Model Performance (accuracy trends, version comparison)
3. System Health (CPU, memory, GPU utilization)
4. WebSocket Connections (active, errors, bandwidth)

---

## 4. EXIGENCES NON-FONCTIONNELLES

### 4.1 Performance
| M√©trique | Objectif | Critique |
|----------|----------|----------|
| Latence streaming (P99) | < 100ms | OUI |
| Latence batch (P99) | < 5s | NON |
| Throughput batch | > 1000 req/sec | NON |
| Concurrent WebSocket connections | > 1000 | OUI |
| Model load time | < 2s | OUI |

### 4.2 Scalabilit√©
- **Horizontal scaling:** Services stateless (scale via Docker replicas)
- **Database:** PostgreSQL avec connection pooling (max 100 connections)
- **Cache:** Redis pour rate limiting et r√©sultats temporaires
- **Load balancing:** Nginx ou Traefik devant Rust service

### 4.3 Disponibilit√©
- **Uptime:** 99.5% (acceptable downtime: 3.6h/mois)
- **Graceful shutdown:** Max 30s pour terminer requ√™tes en cours
- **Health checks:** `/health` et `/ready` endpoints
- **Auto-restart:** Docker restart policy: `unless-stopped`

### 4.4 S√©curit√©
- **Authentication:** JWT avec expiration 1h
- **Rate limiting:** 100 req/min par user (Redis)
- **Input validation:** 
  - Audio format check (magic bytes)
  - File size limit (100 MB)
  - Malware scan (optionnel, ClamAV)
- **CORS:** Configurable whitelist domains
- **Secrets:** Variables d'environnement (jamais en dur dans code)

### 4.5 Maintenabilit√©
- **Code coverage:** > 80% (pytest + cargo test)
- **Documentation:** 
  - README complet avec quick start
  - API docs (OpenAPI/Swagger)
  - Architecture docs (diagrammes ASCII)
  - Code comments (docstrings Python, rustdoc)
- **Linting:** 
  - Python: black, flake8, mypy
  - Rust: cargo clippy, cargo fmt
- **Logs:** Structured JSON (structlog + tracing)

### 4.6 Portabilit√©
- **OS:** Linux (Ubuntu 22.04 recommand√©)
- **Container:** Docker 20.10+
- **Orchestration:** Docker Compose (production: Kubernetes-ready)
- **GPU:** CUDA 11.8+ (optionnel pour entra√Ænement)

---

## 5. CONTRAINTES TECHNIQUES

### 5.1 Technologies Impos√©es
**Backend Python:**
- FastAPI 0.104+
- PyTorch 2.1+ (training)
- ONNX 1.15+ (export/optimization)
- SQLAlchemy 2.0+ (ORM)
- Redis-py 5.0+

**Backend Rust:**
- Axum 0.7+ (web framework)
- Tokio 1.35+ (async runtime)
- ONNX Runtime 1.16+ (inference)
- Tower (middleware)
- Tonic (gRPC, optionnel)

**Infrastructure:**
- PostgreSQL 15+
- Redis 7.2+
- Prometheus 2.48+
- Grafana 10.2+

### 5.2 Contraintes d'Int√©gration
- Communication Python ‚Üî Rust: HTTP REST (gRPC en v2)
- Format mod√®le: ONNX uniquement
- Audio format: 16kHz mono PCM (conversion c√¥t√© client)
- API versioning: `/v1/` prefix mandatory

### 5.3 Contraintes R√©glementaires
- **RGPD:** Pas de stockage audio brut au-del√† du traitement (sauf opt-in user)
- **Audit trail:** Log toutes les inf√©rences avec user_id + timestamp
- **Data retention:** 
  - Audio files: 0 jours (suppression imm√©diate post-traitement)
  - Results: 30 jours
  - Logs: 90 jours

---

## 6. LIVRABLES ATTENDUS

### 6.1 Code Source
- [ ] Python ML service (voiceflow-ml/)
- [ ] Rust inference engine (voiceflow-inference/)
- [ ] Tests unitaires et int√©gration (coverage > 80%)
- [ ] Fichiers configuration (docker-compose.yml, prometheus.yml)

### 6.2 Documentation
- [ ] README.md (quick start, architecture, deployment)
- [ ] CAHIER_DES_CHARGES.md (ce document)
- [ ] NOTE_DE_CADRAGE.md (planning d√©taill√©)
- [ ] CONCEPTION_TECHNIQUE.md (architecture, data models, API specs)
- [ ] ARCHITECTURE_FLOW.md (diagrammes flux)
- [ ] API documentation (OpenAPI specs auto-g√©n√©r√©s)

### 6.3 Infrastructure
- [ ] Dockerfiles (Python + Rust multi-stage builds)
- [ ] docker-compose.yml (stack compl√®te)
- [ ] GitHub Actions workflows (CI/CD)
- [ ] Grafana dashboards (JSON configs)
- [ ] Prometheus alerting rules

### 6.4 Tests et Validation
- [ ] Unit tests (pytest + cargo test)
- [ ] Integration tests (API endpoints)
- [ ] E2E tests (streaming workflow complet)
- [ ] Load testing report (wrk ou k6)
- [ ] Performance benchmarks (latency profiling)

---

## 7. CRIT√àRES D'ACCEPTATION

### 7.1 Tests Fonctionnels
| ID | Test | Crit√®re de Succ√®s |
|----|------|-------------------|
| T1 | Upload fichier audio 10s | R√©sultats diarization re√ßus en < 5s |
| T2 | Stream audio 30s via WebSocket | Latence moyenne < 80ms, P99 < 100ms |
| T3 | Entra√Ænement nouveau mod√®le | Mod√®le export√© en ONNX, chargeable par Rust |
| T4 | A/B testing 90/10 | Trafic correctement r√©parti, m√©triques s√©par√©es |
| T5 | 1000 requ√™tes batch simultan√©es | Aucune erreur, throughput > 800 req/sec |

### 7.2 Tests Non-Fonctionnels
| ID | Test | Crit√®re de Succ√®s |
|----|------|-------------------|
| N1 | Code coverage | > 80% (pytest + cargo test) |
| N2 | Docker build time | < 5 min (builds optimis√©s) |
| N3 | Startup time | Stack compl√®te up en < 60s |
| N4 | Memory footprint | Rust service < 500 MB, Python < 2 GB |
| N5 | Security scan | 0 vulnerabilit√©s critiques (Dependabot) |

### 7.3 Crit√®res de Production-Readiness
- [x] Health checks actifs (`/health`, `/ready`)
- [x] Graceful shutdown (SIGTERM handling)
- [x] Structured logging (JSON format)
- [x] Metrics export√©es (Prometheus format)
- [x] Secrets via env vars (pas de hardcoding)
- [x] Error handling exhaustif (pas de panics Rust)
- [x] Input validation compl√®te
- [x] Rate limiting actif
- [x] Documentation API compl√®te

---

## 8. PLANNING INDICATIF

**Dur√©e totale:** 2 jours (16 heures)

**Jour 1 (8h):**
- Phase 1: Documentation (2h)
- Phase 2: Python ML Service Setup (2h)
- Phase 3: Rust Inference Engine Setup (2h)
- Phase 4: Integration Pipeline (2h)

**Jour 2 (8h):**
- Phase 5: Real-Time Streaming (2h)
- Phase 6: MLOps Pipeline (2h)
- Phase 7: Monitoring & Observability (2h)
- Phase 8: Tests & Documentation (2h)

---

## 9. RISQUES ET MITIGATION

| Risque | Probabilit√© | Impact | Mitigation |
|--------|-------------|--------|------------|
| Latence > 100ms streaming | Moyenne | Critique | Profiling continu, ONNX quantization FP16, optimisation Rust |
| Complexit√© inter-service Python-Rust | Faible | Moyen | API contract strict, tests d'int√©gration |
| ONNX export issues (incompatibilit√©s) | Moyenne | Moyen | Tests PyTorch‚ÜíONNX‚ÜíRust d√®s jour 1 |
| Performance PostgreSQL (bottleneck) | Faible | Moyen | Connection pooling, indexes, Redis cache |
| D√©rive mod√®le en production | Faible | Moyen | Monitoring accuracy, alerting, rollback rapide |

---

## 10. GLOSSAIRE

| Terme | D√©finition |
|-------|------------|
| **Speaker Diarization** | Processus d'identification "qui parle quand" dans un audio multi-locuteurs |
| **ONNX** | Open Neural Network Exchange - format standard pour mod√®les ML |
| **WebSocket** | Protocole full-duplex pour communication temps-r√©el client-serveur |
| **Data Mapper** | Pattern architectural s√©parant logique business et acc√®s donn√©es |
| **P99 Latency** | 99√®me percentile de latence (99% des requ√™tes sous cette valeur) |
| **Quantization** | R√©duction pr√©cision mod√®le (FP32‚ÜíFP16‚ÜíINT8) pour acc√©l√©rer inf√©rence |
| **Graceful Shutdown** | Arr√™t propre du service en terminant requ√™tes en cours |

---

## 11. VALIDATION ET APPROBATION

| R√¥le | Nom | Signature | Date |
|------|-----|-----------|------|
| Chef de Projet | [√Ä remplir] | | |
| Tech Lead ML | [√Ä remplir] | | |
| DevOps Lead | [√Ä remplir] | | |
| Client/Sponsor | [√Ä remplir] | | |

---

**Version:** 1.0  
**Date de cr√©ation:** 29 Novembre 2025  
**Auteur:** VoiceFlow Intelligence Team  
**Statut:** ‚úÖ Valid√©
