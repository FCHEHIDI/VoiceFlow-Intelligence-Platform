"""
Export trained Transformer model to ONNX using ABSOLUTELY the legacy path.

This forces the old torch.onnx.export path by setting environment variables
and using the raw PyTorch model (not traced).
"""

import os
# MUST be set before importing torch
os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
os.environ['TORCH_ONNX_EXPERIMENTAL_RUNTIME_TYPE_CHECK'] = '0'

import torch
import torch.onnx
from pathlib import Path
import sys

from models.diarization.model import SophisticatedProductionGradeDiarizationModel


def export_legacy_force(
    checkpoint_path: str,
    output_path: str,
    num_speakers: int = 2,
    hidden_size: int = 256,
):
    """Force use of legacy ONNX exporter."""
    
    print("=" * 60)
    print("üîÑ Exporting with FORCED Legacy Exporter")
    print("=" * 60)
    
    # 1. Load model
    print(f"\n1Ô∏è‚É£ Loading model from: {checkpoint_path}")
    model = SophisticatedProductionGradeDiarizationModel(
        num_speakers=num_speakers,
        hidden_size=hidden_size
    )
    
    checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    print(f"   ‚úì Model loaded successfully!")
    print(f"   ‚îú‚îÄ Epoch: {checkpoint['epoch']}")
    print(f"   ‚îú‚îÄ Val Loss: {checkpoint['val_loss']:.4f}")
    print(f"   ‚îî‚îÄ Val Accuracy: {checkpoint['val_accuracy']:.2f}%")
    
    # 2. Create dummy input
    print(f"\n2Ô∏è‚É£ Creating dummy input...")
    dummy_input = torch.randn(1, 48000)  # 3 seconds at 16kHz
    print(f"   ‚îî‚îÄ Shape: {dummy_input.shape}")
    
    # 3. Test model
    print(f"\n3Ô∏è‚É£ Testing model forward pass...")
    with torch.no_grad():
        output = model(dummy_input)
    print(f"   ‚úì Forward pass successful!")
    print(f"   ‚îî‚îÄ Output shape: {output.shape}")
    
    # 4. Export using DIRECT torch.jit.script -> onnx save
    print(f"\n4Ô∏è‚É£ Using torch.jit.save -> manual ONNX...")
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    # Save as TorchScript first
    jit_path = output_path.with_suffix('.pt')
    print(f"   ‚îú‚îÄ Saving TorchScript to: {jit_path.name}")
    
    with torch.no_grad():
        traced = torch.jit.trace(model, dummy_input)
    torch.jit.save(traced, str(jit_path))
    print(f"   ‚úì TorchScript saved")
    
    # Now load and export to ONNX
    print(f"   ‚îú‚îÄ Loading TorchScript...")
    loaded_model = torch.jit.load(str(jit_path))
    loaded_model.eval()
    
    print(f"   ‚îú‚îÄ Exporting to ONNX...")
    
    # Use torch.onnx._export (internal legacy API)
    try:
        # Try using the internal _export function
        from torch.onnx import utils as onnx_utils
        
        # This should use the old code path
        torch.onnx._export(
            loaded_model,
            dummy_input,
            str(output_path),
            export_params=True,
            opset_version=14,
            do_constant_folding=False,
            input_names=['audio'],
            output_names=['speaker_probabilities'],
            verbose=False,
            operator_export_type=torch.onnx.OperatorExportTypes.ONNX
        )
        print(f"   ‚úì ONNX export successful!")
    except Exception as e:
        print(f"   ‚ö† Internal _export failed: {e}")
        print(f"   ‚îú‚îÄ Trying public torch.onnx.export...")
        
        # Fall back to public API
        torch.onnx.export(
            loaded_model,
            dummy_input,
            str(output_path),
            export_params=True,
            opset_version=14,
            do_constant_folding=False,
            input_names=['audio'],
            output_names=['speaker_probabilities'],
            verbose=False
        )
        print(f"   ‚úì ONNX export successful (public API)!")
    
    print(f"   ‚îî‚îÄ Saved to: {output_path}")
    
    # 5. Verify file exists
    if output_path.exists():
        size_mb = output_path.stat().st_size / (1024 * 1024)
        print(f"\n‚úÖ Export complete!")
        print(f"   ‚îú‚îÄ File: {output_path.name}")
        print(f"   ‚îú‚îÄ Size: {size_mb:.1f} MB")
        print(f"   ‚îî‚îÄ Ready for Rust deployment!")
        
        # Clean up TorchScript file
        if jit_path.exists():
            jit_path.unlink()
            print(f"   ‚îî‚îÄ Cleaned up {jit_path.name}")
    else:
        print(f"\n‚ùå Export failed - file not created")
        sys.exit(1)


def main():
    checkpoint_path = "../models/checkpoints/transformer_diarization_best.pth"
    output_path = "../models/diarization_transformer.onnx"
    
    try:
        export_legacy_force(
            checkpoint_path=checkpoint_path,
            output_path=output_path,
            num_speakers=2,
            hidden_size=256
        )
    except Exception as e:
        print(f"\n‚ùå Export failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
