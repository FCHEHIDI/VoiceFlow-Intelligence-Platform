#!/bin/bash
# Quick deployment and performance test script

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘   VoiceFlow Inference Server - Deployment & Performance Test  â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Activate virtual environment
echo "ðŸ”§ Activating Python environment..."
source /c/Users/Fares/VoiceFlow-Intelligence-Platform/.venv/Scripts/activate

# Install dependencies
echo "ðŸ“¦ Installing dependencies..."
pip install -q fastapi uvicorn aiohttp

# Start inference server in background
echo "ðŸš€ Starting inference server on port 3000..."
cd /c/Users/Fares/VoiceFlow-Intelligence-Platform/VoiceFlow-Intelligence-Platform/voiceflow-ml
python inference_server.py > server.log 2>&1 &
SERVER_PID=$!

echo "   Server PID: $SERVER_PID"
echo "   Waiting for server to start..."
sleep 5

# Check if server is running
if curl -s http://localhost:3000/health > /dev/null 2>&1; then
    echo "âœ… Server is running!"
    echo ""
    
    # Run load test
    echo "ðŸ§ª Running load test..."
    python load_test.py --url http://localhost:3000 --requests 200 --concurrency 20
    
    echo ""
    echo "ðŸ“Š Server metrics available at: http://localhost:3000/metrics"
    echo ""
    echo "Press Enter to stop server and exit..."
    read
    
    # Stop server
    echo "ðŸ›‘ Stopping server..."
    kill $SERVER_PID 2>/dev/null
    echo "âœ… Server stopped"
else
    echo "âŒ Server failed to start. Check server.log for details"
    cat server.log
    kill $SERVER_PID 2>/dev/null
    exit 1
fi
